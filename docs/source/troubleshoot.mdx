# Troubleshooting

This guide aims to provide you the tools and knowledge required to navigate some common issues. If the suggestions listed 
in this guide do not cover your such situation, please refer to the [Asking for Help](#ask-for-help) section to learn where to
find help with your specific issue.

## Loading datasets

### Loading from folder

When creating a dataset from a folder, one of the most common issues is that the file structure does not follow the 
expected format, or there's an issue with the metadata file.

Learn more about required folder structure in corresponding documentation pages:

* [AudioFolder](https://huggingface.co/docs/datasets/audio_dataset#audiofolder)
* [ImageFolder](https://huggingface.co/docs/datasets/image_dataset#imagefolder)

## Uploading datasets to ðŸ¤— Hub

### Authentication issues

If you are experiencing authentication issues when sharing a dataset on ðŸ¤— Hub using `push_to_hub()` and a Hugging Face 
access token:

* Make sure that the Hugging Face token you're using to authenticate yourself is a token with **write** permission.
* On OSX, it may help to clean up all the huggingface.co passwords on your keychain access, as well as reconfigure `git config --global credential.helper osxkeychain`, before using `huggingface-cli login`.

Alternatively, you can use SSH keys to authenticate yourself - read more in the [ðŸ¤— Hub documentation](https://huggingface.co/docs/hub/security-git-ssh).

### `Too Many Requests`

Uploading large datasets via `push_to_hub()` can result in an error: 

```bash
HfHubHTTPError: 429 Client Error: Too Many Requests for url: ...
You have exceeded our hourly quotas for action: commit. We invite you to retry later.
```

If you encounter this issue, you need to upgrade the `datasets` library. At the moment of writing, you need to install `datasets` from source: 

```bash 
pip install git+https://github.com/huggingface/datasets
```

## Issues when creating datasets from custom data

### Pickling issues when using Dataset.from_generator()

When creating a dataset, `IterableDataset.from_generator` and `Dataset.from_generator` expect a "picklable" generator function.
This is required to hash the function using pickle to be able to cache the dataset on disk.

While generator functions are generally "picklable", note that generator objects are not. So if you're using a generator object, 
you will encounter a TypeError like this:

```bash
TypeError: cannot pickle 'generator' object
```

This error can also occur when using a generator function that uses a global object that is not picklable, such as a 
DB connection, for example. If that's the case, you can initialize such object directly inside the generator function to 
avoid this error.

## Asking for help

If the above troubleshooting advice did not help you resolve your issue, reach out for help to the community and the team.

### Forums 

Ask for help on the Hugging Face forums - post your question in the [ðŸ¤—Datasets category](https://discuss.huggingface.co/c/datasets/10) 
Make sure to write a descriptive post with relevant context about your setup and reproducible code to maximize the likelihood that your problem is solved!

### Discord

Post a question on [Discord](http://hf.co/join/discord), and let the team and the community help you.

### GitHub Issues

Create an Issue on the ðŸ¤— Datasets [GitHub repository](https://github.com/huggingface/datasets/issues) if you suspect 
to have found a bug related to the library. Include context regarding the bug and details about your distributed setup
to help us better figure out what's wrong and how we can fix it.
